# -*- coding: utf-8 -*-
"""Faster RCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D3XbTpPHzlRkHl_ibcl1wHVMft1qnL6f
"""


exec(open('Augmentation.py').read())

from Dataset import train_data_loader,valid_data_loader

from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection import FasterRCNN
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import os 
import matplotlib.pyplot as plt
import torch
import torchvision
import numpy as np
import pandas as pd 
import warnings
warnings.simplefilter('ignore')

device=torch.device('cpu:0')



def get_model():
   model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True).to(device)
   num_classes = 2 # 1 class (car) + background
   in_features = model.roi_heads.box_predictor.cls_score.in_features

   # replace pre-trained head with new one
   model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
   return model

model=get_model()

params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.002,
                                momentum=0.9, weight_decay=0.0005)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,
                                                   step_size=3,
                                                   gamma=0.1)



def train(model,optim,train_loader,valid_loader,path,num_of_epochs):
  print('starting training')
  itr=1
  try:
    os.mkdir(path)
  except: path=path

  for epoch in tqdm(range(num_of_epochs)):
    sum_losses=[]
    validation_losses=[]
    for images,targets in train_loader:
      images=list(image.permute(2,0,1).to(device) for image in images)
      targets=[{k:v.to(device) for k,v in t.items()} for t in targets]
      loss_dict=model(images,targets)
      losses=sum(loss for loss in loss_dict.values())
      losses_value=losses.item()
      sum_losses.append(losses_value)
      optim.zero_grad()
      losses.backward()
      optim.step()
  
    with torch.no_grad():
      for val_images,val_targets in valid_data_loader:
        val_images=list(image.permute(2,0,1).to(device) for image in val_images)
        val_targets=[{k:v.to(device) for k,v in t.items()} for t in val_targets]
        val_loss_dict=model(val_images,val_targets)
      val_losses=sum(loss for loss in val_loss_dict.values())
      val_losses_value=val_losses.item()
      validation_losses.append(val_losses_value)


    print(f"epoch: {epoch} , Loss: {np.mean(sum_losses)}, Validation Loss : {np.mean(validation_losses)}")
    torch.save(model.state_dict(),f"{path}/model {np.mean(validation_losses)}.pt")

train(model,optimizer,train_data_loader,valid_data_loader,'../models',4)